{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "from data_util import *\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "import csv\n",
    "import sys\n",
    "csv.field_size_limit(sys.maxsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create required datset using a company system id in string\n",
    "# import time\n",
    "# start_time = time.time()\n",
    "# df = get_csv_by_system(\"417\")\n",
    "# end_time = time.time()\n",
    "# print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function is used to create a KD tree\n",
    "from job titles embedding.\n",
    "'''\n",
    "from sklearn.neighbors import KDTree\n",
    "def create_kd_tree(vecs):\n",
    "    tree = KDTree(vecs, leaf_size=2)  \n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Given a job title query vector and a KD tree, this\n",
    "function returns k nearest neighbour indexes in the\n",
    "KD tree job titles embedding.\n",
    "'''\n",
    "from sklearn.neighbors import KDTree\n",
    "def knn(k, tree, query):           \n",
    "    dist, ind = tree.query(query, k=k)     \n",
    "    return ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_job_titles(row, job_titles_distinct):\n",
    "    if row['job_title'] in job_titles_distinct:\n",
    "        return row;\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function filters all the job titles with insufficient\n",
    "CV data(ie. the number of rows of CVs are less than a predefined\n",
    "threshold such as 90 here).\n",
    "'''\n",
    "def filter_by_cv_count_for_job_title(df):\n",
    "    threshold = 90\n",
    "    df_job_group = df[['job_title', 'text']].groupby('job_title')\n",
    "    df_filtered_cv_count = df_job_group.filter(lambda x: len(x) > threshold) \n",
    "    job_titles_distinct = set(df_filtered_cv_count['job_title'])\n",
    "    df_filtered = df.apply(lambda row: filter_job_titles(row, job_titles_distinct),\\\n",
    "                           axis=1).dropna()\n",
    "    assert len(df_filtered_cv_count) == len(df_filtered)\n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Loading data from a file path.\n",
    "'''\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "file_path = 'data/417_CVs_outcome.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "df = filter_by_cv_count_for_job_title(df)\n",
    "df['interview'] = df['interview'] * 1\n",
    "# df = df.sample(n=35000)\n",
    "# df_interviewed = df.query('interview == 1')\n",
    "# df_failed = df.query('interview == 0')\n",
    "# df = pd.concat([df_interviewed.sample(n=50), df_failed.sample(n=50)])\n",
    "# df.to_csv('data/CVs_outcome_total.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = 'data/CVs_outcome_total.csv'\n",
    "# df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.apply(lambda row: normalize_jobtitle(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_vec_dict = create_jobtitle_vec_dict(df['job_title'])\n",
    "save_obj(job_vec_dict, \"data/job_vec_dict.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_values = list(job_vec_dict.values())\n",
    "tree = create_kd_tree(dict_values)\n",
    "save_obj(tree, \"data/kd_tree.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.apply(lambda row: encoder_jobtitle(row, job_vec_dict), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def split_dataframe(df):\n",
    "    start, end = 0, math.floor(len(df) * 0.6)\n",
    "    train = df[start:end]\n",
    "    start, end = math.floor(len(df) * 0.6), math.floor(len(df) * 0.8)\n",
    "    val = df[start:end]\n",
    "    start, end = math.floor(len(df) * 0.8), len(df)\n",
    "    test = df[start:end]\n",
    "    return train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Split data into training, validation and test set with\n",
    "proportions 60%, 20% and 20% respectively.\n",
    "'''\n",
    "df = df[[\"text\", \"interview\", \"job_title_vec\"]]\n",
    "df_interviewed = df.query('interview == 1')\n",
    "df_failed = df.query('interview == 0')\n",
    "data_interviewed_split = split_dataframe(df_interviewed)\n",
    "data_failed_split = split_dataframe(df_failed)\n",
    "train = shuffle(pd.concat([data_interviewed_split[0], data_failed_split[0]]))\n",
    "val = shuffle(pd.concat([data_interviewed_split[1], data_failed_split[1]]))\n",
    "test = shuffle(pd.concat([data_interviewed_split[2], data_failed_split[2]]))\n",
    "train.to_csv('data/CVs_outcome_train.csv', index=False)\n",
    "val.to_csv('data/CVs_outcome_val.csv', index=False)\n",
    "test.to_csv('data/CVs_outcome_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function calculates the weight for the loss function to use.\n",
    "The weight is calculated by counting all the job title and interview\n",
    "state pairs and normalizing the counts.\n",
    "'''\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "from tqdm import tqdm_notebook\n",
    "import torch\n",
    "from ast import literal_eval\n",
    "def get_loss_weight(df):\n",
    "    weight_dict = collections.defaultdict(float)\n",
    "    job_title_vecs = df['job_title_vec']\n",
    "    interviews = df['interview']\n",
    "    start_time = time.time()\n",
    "    pool = Pool()\n",
    "    for job_title_vec, interview in tqdm_notebook(zip(job_title_vecs, interviews)):\n",
    "        job_title_vec = literal_eval(str(job_title_vec))\n",
    "        pair = (torch.tensor(job_title_vec), torch.tensor(float(interview)))\n",
    "        weight_dict[str(pair)] += 1.0\n",
    "        \n",
    "    length = len(df)\n",
    "    for key, val in weight_dict.items():\n",
    "        weight_dict[key] = val / length\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    end_time = time.time()\n",
    "    print(end_time - start_time)\n",
    "    return weight_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv('data/CVs_outcome_train.csv')\n",
    "val = pd.read_csv('data/CVs_outcome_val.csv')\n",
    "test = pd.read_csv('data/CVs_outcome_test.csv')\n",
    "data_combined = pd.concat([train, val, test])\n",
    "weight_dict = get_loss_weight(data_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configurations\n",
    "epochs = 50\n",
    "embedding_dim = 50\n",
    "hidden_dim = 150\n",
    "\n",
    "batch_size = 16\n",
    "label_dim = len(list(job_vec_dict.values())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data into batches using pytorch.\n",
    "from torchtext import data\n",
    "text_field = data.Field(sequential=True, tokenize=text_tokenize, lower=True)\n",
    "label_field = data.RawField(preprocessing=label_field_preprocessing,\n",
    "                            postprocessing=label_field_postprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, dev_iter, test_iter = load_data(text_field, label_field, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import torch\n",
    "def calc_score(labels, preds):\n",
    "    labels = np.array([label.cpu().data.clone().numpy() for label in labels])\n",
    "    preds = np.array([pred.cpu().data.clone().numpy() for pred in preds])\n",
    "    score = metrics.roc_auc_score(labels, preds)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(labels, preds):   \n",
    "    hits = 0\n",
    "    for i in range(len(labels)):\n",
    "        if labels[i] == preds[i]:\n",
    "            hits += 1.0\n",
    "    return hits / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_mse_loss(preds, labels, weight):\n",
    "    return torch.sum(weight * (preds - labels) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def get_batch_loss_weight(vec_label, state_label, weight_dict):\n",
    "    batch_size = vec_label.size()[0]\n",
    "    weight_batch = []\n",
    "    for i in range(batch_size):\n",
    "        key = str((vec_label[i], state_label[i]))\n",
    "        weight_batch.append(weight_dict[key])\n",
    "    return torch.tensor(np.array(weight_batch, dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def save_checkpoint(state, path):\n",
    "    print(\"=> Saving a new model to path: \" + path)\n",
    "    if os.path.exists(path):\n",
    "        os.system('rm '+ path)\n",
    "    torch.save(state, path)  # save checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reload_checkpoint(path):\n",
    "    checkpoint = torch.load(path)\n",
    "    return checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(load_checkpoint, path):\n",
    "    model = Model(embedding_dim=embedding_dim, hidden_dim=hidden_dim,\n",
    "                label_size=label_dim, batch_size=batch_size, \n",
    "                pretrained_vec=text_field.vocab.vectors)\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda(\"cuda\")\n",
    "    if load_checkpoint:\n",
    "        checkpoint = reload_checkpoint(path)\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "import torch.nn.functional as F\n",
    "def train_epoch(model, train_iter, loss_function, epoch, weight_dict):\n",
    "    optimizer = optim.Adam([para for para in model.parameters() \\\n",
    "                            if para.requires_grad], lr=1e-3)\n",
    "    model.train()\n",
    "    avg_loss = 0.0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    for batch in tqdm_notebook(train_iter, desc='Train epoch ' + str(epoch + 1)):\n",
    "        text, vec_label, state_label = batch.text.cuda(\"cuda\"), \\\n",
    "            batch.job_title_vec.cuda(\"cuda\"), batch.interview.cuda(\"cuda\")\n",
    "        all_labels += list(state_label.data)\n",
    "        model.batch_size = text.data.shape[1]     \n",
    "        model.hidden = model.init_hidden()\n",
    "        model.zero_grad()\n",
    "        outputs = model(text)\n",
    "        state_preds = (F.cosine_similarity(outputs, vec_label) + 1) / 2\n",
    "        all_preds += [pred for pred in state_preds]\n",
    "        batch_weight = \\\n",
    "            get_batch_loss_weight(vec_label.cpu(), state_label.cpu(), weight_dict)\n",
    "        loss_function.weight = batch_weight.cuda(\"cuda\")\n",
    "        loss = loss_function(state_preds, state_label)\n",
    "        avg_loss += loss\n",
    "        loss.backward()\n",
    "#         clip_grad_norm(model.parameters(), 1)\n",
    "#         lr = -1e-3\n",
    "#         for para in model.parameters():\n",
    "#             para.data.add_(lr, para.grad.data)\n",
    "        optimizer.step()\n",
    "        torch.cuda.empty_cache()\n",
    "    avg_loss /= len(train_iter)\n",
    "    score = calc_score(all_labels, all_preds)\n",
    "    loss_function.weight = None        \n",
    "    return avg_loss, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data, loss_function, name):\n",
    "    model.eval()\n",
    "    avg_loss = 0.0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for batch in data:\n",
    "            text, vec_label, state_label = batch.text.cuda(\"cuda\"), \\\n",
    "                batch.job_title_vec.cuda(\"cuda\"), batch.interview.cuda(\"cuda\")\n",
    "            all_labels += list(state_label.data)\n",
    "            model.batch_size = text.data.shape[1]     \n",
    "            model.hidden = model.init_hidden()\n",
    "            outputs = model(text)\n",
    "            state_preds = (F.cosine_similarity(outputs, vec_label) + 1) / 2     \n",
    "            all_preds += [pred for pred in state_preds]\n",
    "            loss = loss_function(state_preds, state_label)\n",
    "            avg_loss += loss\n",
    "            torch.cuda.empty_cache()\n",
    "        avg_loss /= len(data)\n",
    "        score = calc_score(all_labels, all_preds)\n",
    "    print(name + ': loss %.4f score %.4f' % (avg_loss, score))\n",
    "    return avg_loss, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "def predict(data):\n",
    "    out_dir = os.path.abspath(os.path.join(os.path.curdir, \"interview_models\"))\n",
    "    model_path = out_dir + '/best_model_gpu.pth'\n",
    "    model = load_model(True, model_path)\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    for batch in data:\n",
    "        text = batch.text.cuda(\"cuda\")\n",
    "        model.batch_size = text.data.shape[1]\n",
    "        model.hidden = model.init_hidden()\n",
    "        outputs = model(text)ss\n",
    "        all_preds += [x for x in outputs]\n",
    "        torch.cuda.empty_cache()\n",
    "    return all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils import clip_grad_norm\n",
    "\n",
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, label_size, batch_size,\n",
    "                 pretrained_vec, dropout=0.0):\n",
    "        super(Model, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.dropout = dropout\n",
    "        self.num_layers = 1\n",
    "        self.embeddings = nn.Embedding(len(pretrained_vec), embedding_dim)\n",
    "        self.embeddings.weight.data.copy_(pretrained_vec)\n",
    "        self.embeddings.weight.requires_grad = False \n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_dim,\n",
    "                            num_layers = self.num_layers, bidirectional=True)\n",
    "        self.hidden2label = nn.Linear(hidden_dim * 2, label_size)\n",
    "        self.hidden = self.init_hidden()\n",
    "        \n",
    "\n",
    "    def init_hidden(self):\n",
    "        # first is the hidden h\n",
    "        # second is the cell c\n",
    "        if torch.cuda.is_available():\n",
    "            h0 = Variable(torch.zeros(2 * self.num_layers, self.batch_size, \\\n",
    "                                      self.hidden_dim).cuda(\"cuda\"))\n",
    "            c0 = Variable(torch.zeros(2 * self.num_layers, self.batch_size, \\\n",
    "                                      self.hidden_dim).cuda(\"cuda\"))\n",
    "        else:\n",
    "            h0 = Variable(torch.zeros(2 * self.num_layers, self.batch_size, \\\n",
    "                                      self.hidden_dim))\n",
    "            c0 = Variable(torch.zeros(2 * self.num_layers, self.batch_size, \\\n",
    "                                      self.hidden_dim))\n",
    "        return (h0, c0)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "#         x = self.embeddings(sentence).view(len(sentence), self.batch_size, -1)\n",
    "        x = self.embeddings(sentence)\n",
    "        lstm_out, self.hidden = self.lstm(x, self.hidden)\n",
    "        y = self.hidden2label(lstm_out[-1])\n",
    "#         log_probs = F.log_softmax(y, dim=1)\n",
    "        return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_checkpoint = False\n",
    "best_dev_score = 0\n",
    "start_epoch = 0\n",
    "out_dir = os.path.abspath(os.path.join(os.path.curdir, \"interview_models\"))\n",
    "model_path = out_dir + '/model_gpu.pth'\n",
    "if load_checkpoint:\n",
    "    checkpoint = reload_checkpoint(model_path)\n",
    "    best_dev_score = checkpoint['dev_accuracy']\n",
    "    start_epoch = checkpoint['start_epoch']\n",
    "model = load_model(load_checkpoint, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import time, random\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "best_model = model\n",
    "\n",
    "loss_function = nn.BCEWithLogitsLoss()\n",
    "train_scores = []\n",
    "dev_scores = []\n",
    "\n",
    "out_dir = os.path.abspath(os.path.join(os.path.curdir, \"interview_models\"))\n",
    "best_model_path = out_dir + '/best_model_gpu.pth'\n",
    "result_path = out_dir + \"/model_result_gpu.txt\"\n",
    "\n",
    "print(\"Writing to {}\\n\".format(out_dir))\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "for epoch in range(start_epoch, epochs):\n",
    "    if epoch == 0:\n",
    "        result_file = open(result_path, \"w\")\n",
    "    else:\n",
    "        result_file = open(result_path, \"a\")       \n",
    "    train_avg_loss, train_score = \\\n",
    "        train_epoch(model, train_iter, loss_function, epoch, weight_dict)\n",
    "    tqdm.write('Train: loss %.4f score %.4f' % (train_avg_loss, train_score))\n",
    "    result_file.write('Train: loss %.4f score %.4f\\n' % (train_avg_loss, train_score))\n",
    "    dev_avg_loss, dev_score = evaluate(model, dev_iter, loss_function, 'Dev')\n",
    "    result_file.write('Dev: loss %.4f score %.4f\\n' % (dev_avg_loss, dev_score))\n",
    "    train_scores.append(train_score)\n",
    "    dev_scores.append(dev_score)\n",
    " \n",
    "    save_checkpoint({\n",
    "        'start_epoch': epoch + 1,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'dev_accuracy': best_dev_score\n",
    "    }, model_path)\n",
    "    \n",
    "    if dev_score > best_dev_score:\n",
    "        best_dev_score = dev_score\n",
    "        best_model = model\n",
    "        save_checkpoint({\n",
    "            'start_epoch': epoch + 1,\n",
    "            'state_dict': best_model.state_dict(),\n",
    "            'dev_accuracy': best_dev_score\n",
    "        }, best_model_path)\n",
    "    result_file.close()\n",
    "    \n",
    "test_avg_loss, test_score = evaluate(best_model, test_iter, loss_function, 'Final Test')\n",
    "result_file = open(result_path, \"a\")\n",
    "result_file.write('Test: loss %.4f score %.4f\\n' % (test_avg_loss, test_score))\n",
    "result_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = len(train_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "epoch_nums = [i+1 for i in range(epochs)]\n",
    "plt.plot(epoch_nums, train_scores, label='training score', color='r')\n",
    "plt.plot(epoch_nums, dev_scores, label='validation score', color='b')\n",
    "plt.xlabel('Epoch num')\n",
    "plt.ylabel('Auc Roc score')\n",
    "plt.title('Changes in training and validation scores when epoch num increases')\n",
    "plt.legend()\n",
    "plt.savefig('performance_gpu.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict job title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/CVs_outcome_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "preds = predict(test_iter).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm_notebook\n",
    "# pool = Pool()\n",
    "job_vec_dict = load_obj(\"data/job_vec_dict.pickle\")\n",
    "tree = load_obj(\"data/kd_tree.pickle\")\n",
    "dict_values = list(job_vec_dict.values())\n",
    "dict_keys = list(job_vec_dict.keys())\n",
    "titles_preds = []\n",
    "for i in tqdm_notebook(range(len(preds))):\n",
    "    query = np.array([preds[i].data.clone().numpy()])\n",
    "    ind = list(knn(1, tree, query)[0])\n",
    "    titles_preds.append(dict_keys[ind[0]])\n",
    "# pool.close()\n",
    "# pool.join() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(titles_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_preds = list(set(titles_preds))\n",
    "embeddings_preds = encode_sentences(titles_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=50)\n",
    "embeddings_pca = pca.fit_transform(embeddings_preds)\n",
    "print(sum(pca.explained_variance_ratio_))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_components = 2\n",
    "embeddings_tsne = TSNE(n_components=n_components, verbose=2).fit_transform(embeddings_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colors = ['#630C3A', '#39C8C6', '#D3500C', '#FFB139', \"#00FFFF\"]\n",
    "fig, ax = plt.subplots(figsize=(100,100))\n",
    "ax.scatter(embeddings_tsne[:,0], embeddings_tsne[:,1])\n",
    "for i, txt in enumerate(titles_preds):\n",
    "    ax.annotate(txt, (embeddings_tsne[i,0], embeddings_tsne[i,1]))\n",
    "#     ax.scatter(embeddings_tsne[i,0], embeddings_tsne[i,1], color=colors[clusters.labels_[i]])\n",
    "plt.xlabel(\"job title tnse x\", fontsize=35)\n",
    "plt.ylabel(\"job title tnse y\", fontsize=35)\n",
    "plt.title(\"visualisation of job average embedding into dimension of \" + str(n_components), fontsize=35)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
